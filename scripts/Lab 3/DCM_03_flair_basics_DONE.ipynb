{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCM_03_flair_basics_DONE.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx1RbCcjCpuU"
      },
      "source": [
        "# FLAIR BASICS\n",
        "\n",
        "Check the documentation and tutorials: \n",
        "\n",
        "https://github.com/flairNLP/flair/tree/master/resources/docs\n",
        "\n",
        "Flair is a state of the art neural toolkit to perform sequence labelling and text classification.\n",
        "\n",
        "The aim of this lab is to learn how to install Flair, understand the intuitions about the character-based contextual word representations and getting familiar with its API, which is built around the Token and Sentence objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQCUHxFt3GYh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e985e71-d9e6-44e4-e19c-f1feafe1310f"
      },
      "source": [
        "# !pip install --upgrade git+https://github.com/flairNLP/flair.git\n",
        "# !pip install --upgrade pip\n",
        "\n",
        "!pip install flair==0.8"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flair==0.8 in /usr/local/lib/python3.7/dist-packages (0.8)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (6.1.1)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.3)\n",
            "Requirement already satisfied: janome in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.4.2)\n",
            "Requirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.19.5)\n",
            "Requirement already satisfied: gdown==3.12.2 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (3.12.2)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.5.11)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (2.8.2)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.1.2)\n",
            "Requirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (3.6.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (4.2.6)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.4.0)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.2.13)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.8.9)\n",
            "Requirement already satisfied: sentencepiece==0.1.95 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.1.95)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.10.0+cu111)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (2019.12.20)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.0.9)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (0.3.3)\n",
            "Requirement already satisfied: konoha<5.0.0,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (4.6.5)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (1.7.0)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (4.62.3)\n",
            "Requirement already satisfied: transformers>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from flair==0.8) (4.16.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.8) (3.6.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.8) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown==3.12.2->flair==0.8) (1.15.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair==0.8) (1.13.3)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair==0.8) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair==0.8) (5.2.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.8) (4.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.8) (0.16.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair==0.8) (2.6.3)\n",
            "Requirement already satisfied: overrides<4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair==0.8) (3.1.0)\n",
            "Requirement already satisfied: importlib-metadata<4.0.0,>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konoha<5.0.0,>=4.0.0->flair==0.8) (3.10.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.8) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.8) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair==0.8) (1.3.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair==0.8) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair==0.8) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->flair==0.8) (3.10.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair==0.8) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair==0.8) (21.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair==0.8) (0.11.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair==0.8) (0.0.47)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy->flair==0.8) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata<4.0.0,>=3.7.0->konoha<5.0.0,>=4.0.0->flair==0.8) (3.7.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.8) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.8) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.8) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.8) (2021.10.8)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown==3.12.2->flair==0.8) (1.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair==0.8) (7.1.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIZTbJw_7RNE"
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "from flair.models import TextClassifier"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOK_QbPH7bjL"
      },
      "source": [
        "# \"use_tokenizer\" parameter for tokenizing the input text\n",
        "\n",
        "sentence = Sentence('Washington University, which is located in Missouri, is named after George Washington.', use_tokenizer=False)\n",
        "tokenized_sentence = Sentence('Washington University, which is located in Missouri, is named after George Washington.', use_tokenizer=True)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsoP6Y1lfVm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4e18b1e-fffa-4bd5-b693-b1b70971bc30"
      },
      "source": [
        "print(sentence)\n",
        "print(tokenized_sentence)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: \"Washington University, which is located in Missouri, is named after George Washington.\"   [− Tokens: 12]\n",
            "Sentence: \"Washington University , which is located in Missouri , is named after George Washington .\"   [− Tokens: 15]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feAJDSkZg_ld",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ce47b4-47a7-4856-bca9-c27aa7cbf9ea"
      },
      "source": [
        "## get_token() function retrieves the token by index (starting from 1)\n",
        "print(sentence.get_token(3))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: 3 which\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmQ1bKIthTEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0869edb-33db-4cba-c5bd-a436ae5124ef"
      },
      "source": [
        "## indexes to obtain the tokens (starting from 0)\n",
        "print(sentence[2])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: 3 which\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FM53HBb9hkx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57505650-678e-4f64-9d8d-d6ff1d2b9cad"
      },
      "source": [
        "for token in sentence:\n",
        "  print(token)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: 1 Washington\n",
            "Token: 2 University,\n",
            "Token: 3 which\n",
            "Token: 4 is\n",
            "Token: 5 located\n",
            "Token: 6 in\n",
            "Token: 7 Missouri,\n",
            "Token: 8 is\n",
            "Token: 9 named\n",
            "Token: 10 after\n",
            "Token: 11 George\n",
            "Token: 12 Washington.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awDYkCnGENuD"
      },
      "source": [
        "# WORD REPRESENTATIONS\n",
        "\n",
        "1. Static Word Embeddings (fastText, Glove, etc.)\n",
        "2. Flair character-based contextual embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmDWPSl4phOQ"
      },
      "source": [
        "from flair.embeddings import WordEmbeddings\n",
        "\n",
        "# init embedding\n",
        "en_embedding = WordEmbeddings('glove')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTWM9876qHoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f053cb3f-a001-4476-e98c-d4402861086e"
      },
      "source": [
        "#sentence = Sentence('Washington University, which is located in Missouri, is named after George Washington.')\n",
        "\n",
        "# Obtain vector-based representation from glove pre-trained model\n",
        "en_embedding.embed(sentence)\n",
        "\n",
        "# print the vector representing each word in the sentence\n",
        "for token in sentence:\n",
        "    print(token)\n",
        "    print(token.embedding)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: 1 Washington\n",
            "tensor([-2.2048e-01, -1.1316e-01,  9.4277e-01, -3.9024e-01,  2.5004e-01,\n",
            "        -4.1651e-01, -1.4640e-01,  2.3628e-03, -1.2966e-01, -1.1173e-01,\n",
            "        -2.1546e-01, -8.6271e-01,  1.3817e-01,  3.3118e-01, -6.6500e-01,\n",
            "         3.7134e-01,  2.0050e-01, -3.4055e-01, -1.2422e+00, -7.6653e-01,\n",
            "        -1.1253e-02,  3.8440e-01, -5.0105e-02, -1.8869e-01,  1.0785e-01,\n",
            "         1.7502e-01, -1.0167e-01, -5.7925e-01,  2.3529e-01,  3.2626e-02,\n",
            "         3.2353e-01,  9.7457e-01,  4.5231e-01,  4.9740e-01, -8.8874e-01,\n",
            "         4.9170e-01,  1.1230e-01, -2.1484e-01,  9.3187e-02,  4.7039e-01,\n",
            "        -7.8776e-01, -6.8219e-01, -2.3741e-01,  2.2351e-01,  2.0269e-01,\n",
            "        -1.0166e+00,  1.3095e-01, -2.3654e-01,  3.1501e-01, -3.1880e-01,\n",
            "         5.9744e-01, -2.8722e-01,  2.9970e-01,  3.4877e-01, -1.6597e-01,\n",
            "        -2.8483e+00,  3.2219e-01, -7.8469e-01,  1.3754e+00,  1.5050e-01,\n",
            "        -8.5193e-01,  2.5303e-01,  2.0142e-01, -5.9176e-01,  8.9212e-02,\n",
            "        -3.5561e-01,  2.6522e-01,  1.1283e+00, -3.7250e-01,  9.4010e-01,\n",
            "        -5.2708e-01, -4.6361e-01, -8.1034e-01, -3.3479e-01,  1.0260e-01,\n",
            "        -4.1905e-01,  6.3775e-01,  4.5096e-02, -1.2385e+00,  2.1903e-01,\n",
            "         4.9145e-01,  3.6583e-01, -3.2024e-01, -5.1061e-02, -6.5049e-01,\n",
            "        -1.1894e-02,  2.0887e-01,  2.5857e-01, -2.3303e-01, -8.4911e-01,\n",
            "        -1.5466e-01, -3.3714e-01, -3.7272e-01, -2.9143e-01, -1.2799e+00,\n",
            "         2.8781e-01,  2.9473e-01, -3.2733e-01,  6.3016e-01,  3.6249e-01],\n",
            "       device='cuda:0')\n",
            "Token: 2 University,\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.], device='cuda:0')\n",
            "Token: 3 which\n",
            "tensor([ 3.0240e-02,  4.4606e-01,  4.3166e-01, -3.7528e-01,  2.9068e-01,\n",
            "         2.3032e-01,  1.8125e-01,  4.0201e-01,  1.3518e-01, -1.9562e-01,\n",
            "         3.0639e-01, -1.3239e-01,  6.7897e-01,  4.2234e-01,  3.2637e-01,\n",
            "        -1.5281e-01,  3.7698e-01, -2.3303e-01, -3.3817e-01,  3.0588e-01,\n",
            "         4.4918e-01, -8.3624e-01,  5.9146e-01,  2.4958e-01,  3.9986e-01,\n",
            "        -5.0172e-01, -2.3544e-01, -1.4696e-01, -3.5144e-01, -5.6852e-01,\n",
            "         8.9540e-02,  8.2612e-01, -2.6586e-01,  3.9030e-01, -3.6849e-02,\n",
            "         4.8257e-01,  7.1664e-01,  1.1004e-01, -5.9354e-01, -3.3216e-01,\n",
            "        -2.5736e-01, -3.4531e-01, -2.6326e-02, -2.3747e-01,  1.9656e-04,\n",
            "        -2.7480e-01,  3.8512e-01, -3.9581e-01,  1.1404e-01, -2.5174e-01,\n",
            "        -3.2470e-01,  8.9608e-02,  2.4929e-01,  1.5127e+00, -1.9762e-01,\n",
            "        -2.8509e+00, -5.3833e-01, -4.7111e-01,  1.7859e+00,  7.8126e-01,\n",
            "        -1.2963e-01,  5.6077e-01,  3.2151e-01,  3.5571e-01,  8.4547e-01,\n",
            "         1.4931e-01,  1.1487e-01,  3.0625e-01,  5.4774e-01, -5.0426e-01,\n",
            "         3.3824e-01, -6.2043e-01, -1.2869e-02,  6.6666e-02,  6.2731e-02,\n",
            "        -4.4534e-01,  1.5541e-01,  2.1801e-01, -1.7320e+00,  4.2054e-01,\n",
            "         3.6319e-01, -7.2258e-02, -7.4811e-01,  1.9888e-01, -1.4461e+00,\n",
            "        -2.7576e-01,  2.6646e-01, -5.7838e-01,  5.6151e-01, -2.8701e-02,\n",
            "        -2.4660e-01, -4.2500e-01, -5.7154e-01,  3.1939e-01, -2.2075e-01,\n",
            "         4.6528e-01, -1.6606e-01, -7.9923e-01,  8.0849e-01,  3.7378e-01],\n",
            "       device='cuda:0')\n",
            "Token: 4 is\n",
            "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
            "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
            "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
            "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
            "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
            "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
            "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
            "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
            "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
            "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
            "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
            "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
            "        -0.0442, -1.2969,  0.7622,  0.4635], device='cuda:0')\n",
            "Token: 5 located\n",
            "tensor([-0.3259, -0.0977,  0.4929,  0.5785,  0.0600,  0.1727, -0.2408,  1.1679,\n",
            "         0.3066, -0.0685,  0.3392, -0.1444,  0.8911,  0.2538,  0.3281, -0.8504,\n",
            "         0.9990,  0.0704, -0.7729,  0.1591,  0.3662,  1.2885,  0.6803, -0.1153,\n",
            "        -0.4641, -0.8220,  0.5264,  0.0250, -0.3565,  0.3435, -0.4078,  0.1170,\n",
            "         1.0752,  0.8914,  0.5610,  0.1422,  0.2339,  0.0219,  0.2791,  0.0548,\n",
            "         0.4955, -0.7159, -0.2975, -0.4888,  0.7659,  0.4937,  0.9453,  0.4742,\n",
            "         0.1847,  1.0986, -0.2204,  0.0127,  0.2676,  0.3564, -0.8907, -2.6910,\n",
            "        -0.6626, -1.1894,  1.4337,  0.0867,  0.0597,  0.7623,  0.7843,  0.5301,\n",
            "         0.3194,  0.0225,  0.2144,  0.0696,  0.5294,  0.7360, -0.0974, -0.1481,\n",
            "         0.2401, -0.2745,  0.5444, -0.7322,  0.9958,  0.2988, -0.2035,  0.1765,\n",
            "        -0.4184,  0.2860, -1.0497,  0.0569,  0.2900,  0.4441,  0.0429, -0.7129,\n",
            "         1.2021,  0.1814, -0.2566, -0.2002, -0.3269,  0.5788, -0.8189,  0.6666,\n",
            "        -0.2440, -1.0820,  1.1991, -0.0523], device='cuda:0')\n",
            "Token: 6 in\n",
            "tensor([ 0.0857, -0.2220,  0.1657,  0.1337,  0.3824,  0.3540,  0.0129,  0.2246,\n",
            "        -0.4382,  0.5016, -0.3587, -0.3498,  0.0552,  0.6965, -0.1796,  0.0679,\n",
            "         0.3910,  0.1604, -0.2664, -0.2114,  0.5370,  0.4938,  0.9366,  0.6690,\n",
            "         0.2179, -0.4664,  0.2238, -0.3620, -0.1766,  0.1748, -0.2037,  0.1393,\n",
            "         0.0198, -0.1041, -0.2024,  0.5500, -0.1546,  0.9865, -0.2686, -0.2909,\n",
            "        -0.3287, -0.3419, -0.1694, -0.4200, -0.0467, -0.1633,  0.7082, -0.7491,\n",
            "        -0.0916, -0.9618, -0.1975,  0.1028,  0.5522,  1.3816, -0.6564, -3.2502,\n",
            "        -0.3156, -1.2055,  1.7709,  0.4026, -0.7983,  1.1597, -0.3304,  0.3138,\n",
            "         0.7739,  0.2260,  0.5247, -0.0341,  0.3205,  0.0799,  0.1775, -0.4943,\n",
            "        -0.7005, -0.4457,  0.1724,  0.2028,  0.0233, -0.2068, -1.0158,  0.1832,\n",
            "         0.5675,  0.3182, -0.6501,  0.6828, -0.8658, -0.0594, -0.2926, -0.5567,\n",
            "        -0.3471, -0.3289,  0.4022, -0.1275, -0.2023,  0.8737, -0.5450,  0.7921,\n",
            "        -0.2069, -0.0743,  0.7581, -0.3424], device='cuda:0')\n",
            "Token: 7 Missouri,\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.], device='cuda:0')\n",
            "Token: 8 is\n",
            "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
            "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
            "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
            "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
            "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
            "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
            "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
            "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
            "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
            "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
            "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
            "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
            "        -0.0442, -1.2969,  0.7622,  0.4635], device='cuda:0')\n",
            "Token: 9 named\n",
            "tensor([-0.3516, -0.1663,  0.3655, -0.3684,  0.2747, -0.1548,  0.4861, -0.0217,\n",
            "        -0.5534, -0.0798, -0.3784, -0.1086,  0.8104, -0.0225,  0.3513, -0.3454,\n",
            "         1.4764, -0.1031, -1.0180,  0.6877, -0.3879,  0.2693, -0.1971,  0.0187,\n",
            "         0.4329, -0.2141, -0.1406, -0.5489,  0.1550,  0.5489,  0.0804,  0.6596,\n",
            "         0.2833,  0.2851,  0.4042,  0.1460, -0.3615,  0.2548,  0.1282, -0.2636,\n",
            "        -0.2533,  0.3237,  0.6622, -0.4780,  0.6232,  0.6496, -0.4423,  0.0062,\n",
            "        -0.0396,  0.4655, -0.4053,  0.1261,  0.8087,  0.8531, -0.4349, -2.2792,\n",
            "        -0.8602, -0.1126,  0.5434,  0.6340, -0.0577,  0.7507,  0.1123,  0.2812,\n",
            "         0.9433, -0.7431,  0.2454,  0.7698,  0.5878,  0.7000,  0.1028, -0.1339,\n",
            "        -0.5746, -0.3237, -0.3334,  0.0385,  0.3300, -0.1217, -0.6153, -0.6244,\n",
            "         0.0891, -0.0047, -0.4819,  0.0180, -0.4557, -0.6658, -0.1686, -0.6777,\n",
            "         0.7518, -0.7094,  0.1465, -0.1562, -0.0856,  0.5049, -0.3004,  0.1565,\n",
            "        -0.7611, -0.5038,  0.1150, -0.8237], device='cuda:0')\n",
            "Token: 10 after\n",
            "tensor([ 3.7711e-01, -3.4471e-01,  1.3405e-01, -1.1710e-02, -1.9427e-01,\n",
            "         4.1464e-01,  4.0608e-01,  4.3063e-01, -5.7060e-02, -1.9921e-01,\n",
            "         4.3267e-01, -1.6269e-02,  2.1710e-01, -2.6149e-03,  3.9424e-01,\n",
            "        -4.2803e-01, -1.7495e-02, -5.6658e-01, -4.4558e-01, -1.8529e-01,\n",
            "         2.6732e-01, -1.5712e-01,  2.1657e-01,  7.9714e-01,  6.9623e-01,\n",
            "         2.0405e-01, -4.9907e-01, -4.5519e-01,  3.8210e-01,  2.0603e-01,\n",
            "        -2.1606e-01,  1.0093e-01, -5.0148e-01, -1.1058e-01, -4.3455e-01,\n",
            "        -2.6785e-01, -2.0234e-01,  3.8320e-03, -4.9108e-01, -1.7642e-01,\n",
            "        -8.8971e-01, -2.7900e-01,  8.6387e-01, -1.7356e-02,  3.1210e-01,\n",
            "         4.1004e-01,  2.3199e-01, -6.0812e-01,  4.4763e-01, -8.9579e-01,\n",
            "        -3.8491e-02, -2.5772e-01,  3.9468e-01,  1.6186e+00, -5.4882e-01,\n",
            "        -3.0291e+00, -7.7845e-01, -3.2463e-01,  1.7658e+00,  9.7303e-01,\n",
            "        -3.9342e-01,  5.4811e-01,  1.3164e-02,  3.7850e-01,  2.4538e-01,\n",
            "         3.1079e-02,  2.3628e-01,  2.8901e-01,  2.7047e-02,  2.8985e-01,\n",
            "        -7.4523e-01,  1.1517e-02, -3.9456e-01, -5.7706e-01, -6.3604e-01,\n",
            "         3.1022e-01, -3.8317e-01, -7.7663e-02, -1.3539e+00,  1.8009e-02,\n",
            "         8.5646e-01,  3.8259e-02, -3.9437e-01,  4.4331e-01, -1.0802e+00,\n",
            "        -4.3159e-01,  1.4391e-01,  1.1854e-01, -5.6459e-01, -4.7966e-01,\n",
            "         2.2860e-01, -2.4369e-01, -4.2823e-01,  1.0366e+00, -8.3071e-01,\n",
            "         1.2460e-01,  2.0630e-01,  5.4232e-01,  1.1425e-01, -6.6927e-01],\n",
            "       device='cuda:0')\n",
            "Token: 11 George\n",
            "tensor([-4.4295e-01,  5.9694e-02,  7.8306e-02, -2.4619e-01,  2.8411e-02,\n",
            "        -6.3084e-01,  3.7209e-02, -1.6568e-01, -7.3036e-01, -6.8152e-01,\n",
            "        -1.5946e-01, -4.4025e-01, -5.3630e-01,  2.4174e-01,  7.7513e-02,\n",
            "        -3.1366e-01,  3.3539e-01, -1.4214e-01, -1.2390e+00,  1.6170e-01,\n",
            "        -1.3486e-01, -2.2743e-01,  4.4955e-01, -7.2688e-01,  2.5063e-01,\n",
            "         1.1166e-01, -6.2308e-01, -5.5884e-01,  5.1252e-01,  3.6855e-01,\n",
            "         2.9996e-01,  7.0179e-01,  6.7464e-01,  4.0543e-01, -3.0825e-01,\n",
            "         8.3837e-01, -1.8986e-01, -1.7278e-01, -2.1306e-01,  3.5070e-01,\n",
            "        -4.1994e-01, -9.9697e-02,  7.5963e-01,  3.2975e-01, -2.2113e-01,\n",
            "        -1.2372e-01, -5.1361e-01, -6.8517e-01, -6.5545e-02, -1.7642e-01,\n",
            "         6.0858e-01, -7.4822e-02,  9.6863e-01,  5.0805e-01,  2.6777e-01,\n",
            "        -2.7093e+00, -1.0079e-01, -1.2588e-01,  1.2641e-01, -1.2384e-01,\n",
            "         4.0576e-01,  5.5333e-01,  1.5053e-01, -9.6734e-02,  2.8402e-01,\n",
            "        -2.3382e-01,  4.7452e-02,  1.4050e+00, -2.7471e-01,  6.4243e-01,\n",
            "        -5.1403e-01,  1.8748e-01, -9.9874e-01, -3.7344e-01, -1.4193e-01,\n",
            "        -2.7153e-01,  3.0842e-01,  9.3234e-01, -3.8388e-01,  3.6608e-01,\n",
            "         7.3780e-01, -1.7734e-01,  2.0051e-02, -2.4361e-01, -5.7102e-01,\n",
            "        -2.7266e-01, -5.6562e-01, -7.4104e-01,  1.6745e-01, -1.3076e+00,\n",
            "        -3.5900e-01, -7.5738e-01, -1.0948e-01,  5.3662e-01, -1.0914e+00,\n",
            "        -1.0287e-01,  5.8263e-04, -4.5603e-01, -4.7270e-02, -6.7599e-01],\n",
            "       device='cuda:0')\n",
            "Token: 12 Washington.\n",
            "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0.], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC2ydyh9GEpG",
        "outputId": "32e47127-9750-43c8-a27e-fcf4c0c4ba7c"
      },
      "source": [
        "# Washington embedding \"Washington University\"\n",
        "sentence[0].get_embedding()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-2.2048e-01, -1.1316e-01,  9.4277e-01, -3.9024e-01,  2.5004e-01,\n",
              "        -4.1651e-01, -1.4640e-01,  2.3628e-03, -1.2966e-01, -1.1173e-01,\n",
              "        -2.1546e-01, -8.6271e-01,  1.3817e-01,  3.3118e-01, -6.6500e-01,\n",
              "         3.7134e-01,  2.0050e-01, -3.4055e-01, -1.2422e+00, -7.6653e-01,\n",
              "        -1.1253e-02,  3.8440e-01, -5.0105e-02, -1.8869e-01,  1.0785e-01,\n",
              "         1.7502e-01, -1.0167e-01, -5.7925e-01,  2.3529e-01,  3.2626e-02,\n",
              "         3.2353e-01,  9.7457e-01,  4.5231e-01,  4.9740e-01, -8.8874e-01,\n",
              "         4.9170e-01,  1.1230e-01, -2.1484e-01,  9.3187e-02,  4.7039e-01,\n",
              "        -7.8776e-01, -6.8219e-01, -2.3741e-01,  2.2351e-01,  2.0269e-01,\n",
              "        -1.0166e+00,  1.3095e-01, -2.3654e-01,  3.1501e-01, -3.1880e-01,\n",
              "         5.9744e-01, -2.8722e-01,  2.9970e-01,  3.4877e-01, -1.6597e-01,\n",
              "        -2.8483e+00,  3.2219e-01, -7.8469e-01,  1.3754e+00,  1.5050e-01,\n",
              "        -8.5193e-01,  2.5303e-01,  2.0142e-01, -5.9176e-01,  8.9212e-02,\n",
              "        -3.5561e-01,  2.6522e-01,  1.1283e+00, -3.7250e-01,  9.4010e-01,\n",
              "        -5.2708e-01, -4.6361e-01, -8.1034e-01, -3.3479e-01,  1.0260e-01,\n",
              "        -4.1905e-01,  6.3775e-01,  4.5096e-02, -1.2385e+00,  2.1903e-01,\n",
              "         4.9145e-01,  3.6583e-01, -3.2024e-01, -5.1061e-02, -6.5049e-01,\n",
              "        -1.1894e-02,  2.0887e-01,  2.5857e-01, -2.3303e-01, -8.4911e-01,\n",
              "        -1.5466e-01, -3.3714e-01, -3.7272e-01, -2.9143e-01, -1.2799e+00,\n",
              "         2.8781e-01,  2.9473e-01, -3.2733e-01,  6.3016e-01,  3.6249e-01],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5U-FL5l8lit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca15174-d590-4128-af3d-19564a1d19eb"
      },
      "source": [
        "# Washington embedding in \"George Washington\"\n",
        "sentence[11].get_embedding()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvFXLP5kH5xZ"
      },
      "source": [
        "## ASSIGNMENT 1\n",
        "\n",
        "In theory, the representations for tokens sentence[0] and sentence[11] should be the same (same glove vector representation).\n",
        "\n",
        "+ Write code to establish whether the vectors are actually the same. The output should look like the one below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBSncHO3uYKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be1f441-ec69-4d32-87f0-14cc7bf400f6"
      },
      "source": [
        "# TODO: why is this False?\n",
        "sentence[0].get_embedding() == sentence[11].get_embedding()\n",
        "\n",
        "#compares each element of the vector and as it is different returns \"false\"."
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2asTF-XjImdt"
      },
      "source": [
        "+ TODO: You need to find out why this is the case.\n",
        "+ TODO: Once you find out, write code to obtain the embeddings again and to establish that they are indeed the same representations (for both occurrences of 'Washington')."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fp6WF1ngyzjr"
      },
      "source": [
        "# TODO: obtain new representation using the glove embeddings and compare them again.\n",
        "\n",
        "\n",
        "# TODO: You need to find out why this is the case\n",
        "#The first embedding is \"Washington\" but the second is \"Washington.\" . By not tokenizing the phrase you run this risk."
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print tokens\n",
        "en_embedding.embed(tokenized_sentence)\n",
        "\n",
        "\n",
        "for token in  tokenized_sentence:\n",
        "  print (token)\n",
        "\n",
        "#print vectors\n",
        "\n",
        "for token in tokenized_sentence:\n",
        "  print(token.embedding)\n",
        "\n",
        "\n",
        "tokenized_sentence[0].get_embedding() == tokenized_sentence[13].get_embedding()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c24cAga4t395",
        "outputId": "574384f8-8bb4-4d67-84b0-5ef48438435e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: 1 Washington\n",
            "Token: 2 University\n",
            "Token: 3 ,\n",
            "Token: 4 which\n",
            "Token: 5 is\n",
            "Token: 6 located\n",
            "Token: 7 in\n",
            "Token: 8 Missouri\n",
            "Token: 9 ,\n",
            "Token: 10 is\n",
            "Token: 11 named\n",
            "Token: 12 after\n",
            "Token: 13 George\n",
            "Token: 14 Washington\n",
            "Token: 15 .\n",
            "tensor([-2.2048e-01, -1.1316e-01,  9.4277e-01, -3.9024e-01,  2.5004e-01,\n",
            "        -4.1651e-01, -1.4640e-01,  2.3628e-03, -1.2966e-01, -1.1173e-01,\n",
            "        -2.1546e-01, -8.6271e-01,  1.3817e-01,  3.3118e-01, -6.6500e-01,\n",
            "         3.7134e-01,  2.0050e-01, -3.4055e-01, -1.2422e+00, -7.6653e-01,\n",
            "        -1.1253e-02,  3.8440e-01, -5.0105e-02, -1.8869e-01,  1.0785e-01,\n",
            "         1.7502e-01, -1.0167e-01, -5.7925e-01,  2.3529e-01,  3.2626e-02,\n",
            "         3.2353e-01,  9.7457e-01,  4.5231e-01,  4.9740e-01, -8.8874e-01,\n",
            "         4.9170e-01,  1.1230e-01, -2.1484e-01,  9.3187e-02,  4.7039e-01,\n",
            "        -7.8776e-01, -6.8219e-01, -2.3741e-01,  2.2351e-01,  2.0269e-01,\n",
            "        -1.0166e+00,  1.3095e-01, -2.3654e-01,  3.1501e-01, -3.1880e-01,\n",
            "         5.9744e-01, -2.8722e-01,  2.9970e-01,  3.4877e-01, -1.6597e-01,\n",
            "        -2.8483e+00,  3.2219e-01, -7.8469e-01,  1.3754e+00,  1.5050e-01,\n",
            "        -8.5193e-01,  2.5303e-01,  2.0142e-01, -5.9176e-01,  8.9212e-02,\n",
            "        -3.5561e-01,  2.6522e-01,  1.1283e+00, -3.7250e-01,  9.4010e-01,\n",
            "        -5.2708e-01, -4.6361e-01, -8.1034e-01, -3.3479e-01,  1.0260e-01,\n",
            "        -4.1905e-01,  6.3775e-01,  4.5096e-02, -1.2385e+00,  2.1903e-01,\n",
            "         4.9145e-01,  3.6583e-01, -3.2024e-01, -5.1061e-02, -6.5049e-01,\n",
            "        -1.1894e-02,  2.0887e-01,  2.5857e-01, -2.3303e-01, -8.4911e-01,\n",
            "        -1.5466e-01, -3.3714e-01, -3.7272e-01, -2.9143e-01, -1.2799e+00,\n",
            "         2.8781e-01,  2.9473e-01, -3.2733e-01,  6.3016e-01,  3.6249e-01],\n",
            "       device='cuda:0')\n",
            "tensor([ 0.6958, -0.1933, -0.7813, -0.4559,  0.2925,  0.3648,  0.4204,  0.3944,\n",
            "        -0.8260,  0.9515, -0.5746, -0.6088,  0.1764,  1.2112, -0.4096, -0.3099,\n",
            "         1.0360,  0.1446, -0.6612, -0.1530, -0.6027,  0.4377,  0.0996,  0.0846,\n",
            "        -0.1335, -0.6661,  0.3028, -1.2281,  0.2023, -0.0251, -1.0822,  1.2366,\n",
            "         0.0275,  0.4997, -1.3037, -0.5274, -0.7245,  0.6482, -1.0533, -0.0516,\n",
            "        -1.1125, -0.2104, -0.8686, -0.5589, -0.1256, -0.1677,  1.2164,  0.6834,\n",
            "         0.0060,  0.2811,  0.4287, -1.0092,  0.4076, -0.1990, -0.5442, -2.7965,\n",
            "        -0.1189, -0.9814,  1.0011,  0.1349, -0.1668,  0.4366, -0.0222, -0.3068,\n",
            "         0.2698,  0.1801, -0.1242,  1.1771,  0.9027,  1.6263, -0.2043,  0.3313,\n",
            "         0.2568, -0.2361, -0.8155,  0.0435,  0.7348, -0.0136, -0.6192, -0.1236,\n",
            "         0.6251,  0.0567, -0.9702, -0.7868, -1.1703,  0.7142,  0.3694, -0.7578,\n",
            "         0.5150, -0.6268,  0.6761, -0.7994,  0.0793,  0.6695, -0.9211,  0.8140,\n",
            "        -0.2785, -0.3130,  0.9110,  0.1123], device='cuda:0')\n",
            "tensor([-0.1077,  0.1105,  0.5981, -0.5436,  0.6740,  0.1066,  0.0389,  0.3548,\n",
            "         0.0635, -0.0942,  0.1579, -0.8166,  0.1417,  0.2194,  0.5850, -0.5216,\n",
            "         0.2278, -0.1664, -0.6823,  0.3587,  0.4257,  0.1902,  0.9196,  0.5756,\n",
            "         0.4618,  0.4236, -0.0954, -0.4275, -0.1657, -0.0568, -0.2959,  0.2604,\n",
            "        -0.2661, -0.0704, -0.2766,  0.1582,  0.6982,  0.4308,  0.2795, -0.4544,\n",
            "        -0.3380, -0.5818,  0.2236, -0.5778, -0.2686, -0.2042,  0.5639, -0.5852,\n",
            "        -0.1436, -0.6422,  0.0055, -0.3525,  0.1616,  1.1796, -0.4767, -2.7553,\n",
            "        -0.1321, -0.0477,  1.0655,  1.1034, -0.2208,  0.1867,  0.1318,  0.1512,\n",
            "         0.7131, -0.3521,  0.9135,  0.6178,  0.7099,  0.2395, -0.1457, -0.3786,\n",
            "        -0.0460, -0.4737,  0.2385,  0.2054, -0.1900,  0.3251, -1.1112, -0.3634,\n",
            "         0.9868, -0.0848, -0.5401,  0.1173, -1.0194, -0.2442,  0.1277,  0.0139,\n",
            "         0.0804, -0.3541,  0.3495, -0.7226,  0.3755,  0.4441, -0.9906,  0.6121,\n",
            "        -0.3511, -0.8316,  0.4529,  0.0826], device='cuda:0')\n",
            "tensor([ 3.0240e-02,  4.4606e-01,  4.3166e-01, -3.7528e-01,  2.9068e-01,\n",
            "         2.3032e-01,  1.8125e-01,  4.0201e-01,  1.3518e-01, -1.9562e-01,\n",
            "         3.0639e-01, -1.3239e-01,  6.7897e-01,  4.2234e-01,  3.2637e-01,\n",
            "        -1.5281e-01,  3.7698e-01, -2.3303e-01, -3.3817e-01,  3.0588e-01,\n",
            "         4.4918e-01, -8.3624e-01,  5.9146e-01,  2.4958e-01,  3.9986e-01,\n",
            "        -5.0172e-01, -2.3544e-01, -1.4696e-01, -3.5144e-01, -5.6852e-01,\n",
            "         8.9540e-02,  8.2612e-01, -2.6586e-01,  3.9030e-01, -3.6849e-02,\n",
            "         4.8257e-01,  7.1664e-01,  1.1004e-01, -5.9354e-01, -3.3216e-01,\n",
            "        -2.5736e-01, -3.4531e-01, -2.6326e-02, -2.3747e-01,  1.9656e-04,\n",
            "        -2.7480e-01,  3.8512e-01, -3.9581e-01,  1.1404e-01, -2.5174e-01,\n",
            "        -3.2470e-01,  8.9608e-02,  2.4929e-01,  1.5127e+00, -1.9762e-01,\n",
            "        -2.8509e+00, -5.3833e-01, -4.7111e-01,  1.7859e+00,  7.8126e-01,\n",
            "        -1.2963e-01,  5.6077e-01,  3.2151e-01,  3.5571e-01,  8.4547e-01,\n",
            "         1.4931e-01,  1.1487e-01,  3.0625e-01,  5.4774e-01, -5.0426e-01,\n",
            "         3.3824e-01, -6.2043e-01, -1.2869e-02,  6.6666e-02,  6.2731e-02,\n",
            "        -4.4534e-01,  1.5541e-01,  2.1801e-01, -1.7320e+00,  4.2054e-01,\n",
            "         3.6319e-01, -7.2258e-02, -7.4811e-01,  1.9888e-01, -1.4461e+00,\n",
            "        -2.7576e-01,  2.6646e-01, -5.7838e-01,  5.6151e-01, -2.8701e-02,\n",
            "        -2.4660e-01, -4.2500e-01, -5.7154e-01,  3.1939e-01, -2.2075e-01,\n",
            "         4.6528e-01, -1.6606e-01, -7.9923e-01,  8.0849e-01,  3.7378e-01],\n",
            "       device='cuda:0')\n",
            "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
            "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
            "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
            "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
            "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
            "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
            "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
            "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
            "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
            "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
            "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
            "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
            "        -0.0442, -1.2969,  0.7622,  0.4635], device='cuda:0')\n",
            "tensor([-0.3259, -0.0977,  0.4929,  0.5785,  0.0600,  0.1727, -0.2408,  1.1679,\n",
            "         0.3066, -0.0685,  0.3392, -0.1444,  0.8911,  0.2538,  0.3281, -0.8504,\n",
            "         0.9990,  0.0704, -0.7729,  0.1591,  0.3662,  1.2885,  0.6803, -0.1153,\n",
            "        -0.4641, -0.8220,  0.5264,  0.0250, -0.3565,  0.3435, -0.4078,  0.1170,\n",
            "         1.0752,  0.8914,  0.5610,  0.1422,  0.2339,  0.0219,  0.2791,  0.0548,\n",
            "         0.4955, -0.7159, -0.2975, -0.4888,  0.7659,  0.4937,  0.9453,  0.4742,\n",
            "         0.1847,  1.0986, -0.2204,  0.0127,  0.2676,  0.3564, -0.8907, -2.6910,\n",
            "        -0.6626, -1.1894,  1.4337,  0.0867,  0.0597,  0.7623,  0.7843,  0.5301,\n",
            "         0.3194,  0.0225,  0.2144,  0.0696,  0.5294,  0.7360, -0.0974, -0.1481,\n",
            "         0.2401, -0.2745,  0.5444, -0.7322,  0.9958,  0.2988, -0.2035,  0.1765,\n",
            "        -0.4184,  0.2860, -1.0497,  0.0569,  0.2900,  0.4441,  0.0429, -0.7129,\n",
            "         1.2021,  0.1814, -0.2566, -0.2002, -0.3269,  0.5788, -0.8189,  0.6666,\n",
            "        -0.2440, -1.0820,  1.1991, -0.0523], device='cuda:0')\n",
            "tensor([ 0.0857, -0.2220,  0.1657,  0.1337,  0.3824,  0.3540,  0.0129,  0.2246,\n",
            "        -0.4382,  0.5016, -0.3587, -0.3498,  0.0552,  0.6965, -0.1796,  0.0679,\n",
            "         0.3910,  0.1604, -0.2664, -0.2114,  0.5370,  0.4938,  0.9366,  0.6690,\n",
            "         0.2179, -0.4664,  0.2238, -0.3620, -0.1766,  0.1748, -0.2037,  0.1393,\n",
            "         0.0198, -0.1041, -0.2024,  0.5500, -0.1546,  0.9865, -0.2686, -0.2909,\n",
            "        -0.3287, -0.3419, -0.1694, -0.4200, -0.0467, -0.1633,  0.7082, -0.7491,\n",
            "        -0.0916, -0.9618, -0.1975,  0.1028,  0.5522,  1.3816, -0.6564, -3.2502,\n",
            "        -0.3156, -1.2055,  1.7709,  0.4026, -0.7983,  1.1597, -0.3304,  0.3138,\n",
            "         0.7739,  0.2260,  0.5247, -0.0341,  0.3205,  0.0799,  0.1775, -0.4943,\n",
            "        -0.7005, -0.4457,  0.1724,  0.2028,  0.0233, -0.2068, -1.0158,  0.1832,\n",
            "         0.5675,  0.3182, -0.6501,  0.6828, -0.8658, -0.0594, -0.2926, -0.5567,\n",
            "        -0.3471, -0.3289,  0.4022, -0.1275, -0.2023,  0.8737, -0.5450,  0.7921,\n",
            "        -0.2069, -0.0743,  0.7581, -0.3424], device='cuda:0')\n",
            "tensor([ 0.5875, -0.0418,  0.5423, -0.4079,  0.6337, -0.2488,  1.0131,  0.2473,\n",
            "        -0.9812, -0.1715, -0.9286, -0.4213, -0.4062, -0.1835, -0.0759, -0.4948,\n",
            "         0.9084,  0.1608, -0.7684,  0.2119,  0.3319,  0.5954,  0.4027, -0.0084,\n",
            "        -0.9699, -0.0716, -0.6471, -0.6865,  0.2195,  0.0327,  0.3419, -0.0047,\n",
            "         0.6734,  0.0626, -0.7383, -0.6438, -0.3405, -0.5855,  0.5717,  0.4572,\n",
            "        -0.1855, -0.6819, -0.2591, -0.3825, -0.3424, -0.1133,  0.5486, -0.4310,\n",
            "         0.4471, -0.1902, -0.3220, -0.0287,  0.3423, -0.5011, -0.2002, -1.2138,\n",
            "         0.6807, -1.0359,  1.0720,  0.2549, -0.2948,  0.0199,  0.8478,  0.1612,\n",
            "         0.7255, -0.3741,  0.4484,  0.7969,  0.2441,  1.0150, -0.0569, -0.4421,\n",
            "         0.0540,  0.2739,  0.3609, -0.0813,  0.3761, -0.2317, -0.2828, -0.0585,\n",
            "        -0.5368, -0.0136, -0.4584, -0.3554, -0.4937, -0.5653,  0.0438, -0.6586,\n",
            "         0.5951,  0.3026,  0.1299, -0.7120, -0.4676,  1.0162, -1.0639,  0.3048,\n",
            "         0.1056,  0.4797,  0.6065, -0.4948], device='cuda:0')\n",
            "tensor([-0.1077,  0.1105,  0.5981, -0.5436,  0.6740,  0.1066,  0.0389,  0.3548,\n",
            "         0.0635, -0.0942,  0.1579, -0.8166,  0.1417,  0.2194,  0.5850, -0.5216,\n",
            "         0.2278, -0.1664, -0.6823,  0.3587,  0.4257,  0.1902,  0.9196,  0.5756,\n",
            "         0.4618,  0.4236, -0.0954, -0.4275, -0.1657, -0.0568, -0.2959,  0.2604,\n",
            "        -0.2661, -0.0704, -0.2766,  0.1582,  0.6982,  0.4308,  0.2795, -0.4544,\n",
            "        -0.3380, -0.5818,  0.2236, -0.5778, -0.2686, -0.2042,  0.5639, -0.5852,\n",
            "        -0.1436, -0.6422,  0.0055, -0.3525,  0.1616,  1.1796, -0.4767, -2.7553,\n",
            "        -0.1321, -0.0477,  1.0655,  1.1034, -0.2208,  0.1867,  0.1318,  0.1512,\n",
            "         0.7131, -0.3521,  0.9135,  0.6178,  0.7099,  0.2395, -0.1457, -0.3786,\n",
            "        -0.0460, -0.4737,  0.2385,  0.2054, -0.1900,  0.3251, -1.1112, -0.3634,\n",
            "         0.9868, -0.0848, -0.5401,  0.1173, -1.0194, -0.2442,  0.1277,  0.0139,\n",
            "         0.0804, -0.3541,  0.3495, -0.7226,  0.3755,  0.4441, -0.9906,  0.6121,\n",
            "        -0.3511, -0.8316,  0.4529,  0.0826], device='cuda:0')\n",
            "tensor([-0.5426,  0.4148,  1.0322, -0.4024,  0.4669,  0.2182, -0.0749,  0.4733,\n",
            "         0.0810, -0.2208, -0.1281, -0.1144,  0.5089,  0.1157,  0.0282, -0.3628,\n",
            "         0.4382,  0.0475,  0.2028,  0.4986, -0.1007,  0.1327,  0.1697,  0.1165,\n",
            "         0.3135,  0.2571,  0.0928, -0.5683, -0.5297, -0.0515, -0.6733,  0.9253,\n",
            "         0.2693,  0.2273,  0.6636,  0.2622,  0.1972,  0.2609,  0.1877, -0.3454,\n",
            "        -0.4263,  0.1398,  0.5634, -0.5691,  0.1240, -0.1289,  0.7248, -0.2610,\n",
            "        -0.2631, -0.4360,  0.0789, -0.8415,  0.5160,  1.3997, -0.7646, -3.1453,\n",
            "        -0.2920, -0.3125,  1.5129,  0.5243,  0.2146,  0.4245, -0.0884, -0.1780,\n",
            "         1.1876,  0.1058,  0.7657,  0.2191,  0.3582, -0.1164,  0.0933, -0.6248,\n",
            "        -0.2190,  0.2180,  0.7406, -0.4374,  0.1434,  0.1472, -1.1605, -0.0505,\n",
            "         0.1268, -0.0144, -0.9868, -0.0913, -1.2054, -0.1197,  0.0478, -0.5400,\n",
            "         0.5246, -0.7096, -0.3253, -0.1346, -0.4131,  0.3343, -0.0072,  0.3225,\n",
            "        -0.0442, -1.2969,  0.7622,  0.4635], device='cuda:0')\n",
            "tensor([-0.3516, -0.1663,  0.3655, -0.3684,  0.2747, -0.1548,  0.4861, -0.0217,\n",
            "        -0.5534, -0.0798, -0.3784, -0.1086,  0.8104, -0.0225,  0.3513, -0.3454,\n",
            "         1.4764, -0.1031, -1.0180,  0.6877, -0.3879,  0.2693, -0.1971,  0.0187,\n",
            "         0.4329, -0.2141, -0.1406, -0.5489,  0.1550,  0.5489,  0.0804,  0.6596,\n",
            "         0.2833,  0.2851,  0.4042,  0.1460, -0.3615,  0.2548,  0.1282, -0.2636,\n",
            "        -0.2533,  0.3237,  0.6622, -0.4780,  0.6232,  0.6496, -0.4423,  0.0062,\n",
            "        -0.0396,  0.4655, -0.4053,  0.1261,  0.8087,  0.8531, -0.4349, -2.2792,\n",
            "        -0.8602, -0.1126,  0.5434,  0.6340, -0.0577,  0.7507,  0.1123,  0.2812,\n",
            "         0.9433, -0.7431,  0.2454,  0.7698,  0.5878,  0.7000,  0.1028, -0.1339,\n",
            "        -0.5746, -0.3237, -0.3334,  0.0385,  0.3300, -0.1217, -0.6153, -0.6244,\n",
            "         0.0891, -0.0047, -0.4819,  0.0180, -0.4557, -0.6658, -0.1686, -0.6777,\n",
            "         0.7518, -0.7094,  0.1465, -0.1562, -0.0856,  0.5049, -0.3004,  0.1565,\n",
            "        -0.7611, -0.5038,  0.1150, -0.8237], device='cuda:0')\n",
            "tensor([ 3.7711e-01, -3.4471e-01,  1.3405e-01, -1.1710e-02, -1.9427e-01,\n",
            "         4.1464e-01,  4.0608e-01,  4.3063e-01, -5.7060e-02, -1.9921e-01,\n",
            "         4.3267e-01, -1.6269e-02,  2.1710e-01, -2.6149e-03,  3.9424e-01,\n",
            "        -4.2803e-01, -1.7495e-02, -5.6658e-01, -4.4558e-01, -1.8529e-01,\n",
            "         2.6732e-01, -1.5712e-01,  2.1657e-01,  7.9714e-01,  6.9623e-01,\n",
            "         2.0405e-01, -4.9907e-01, -4.5519e-01,  3.8210e-01,  2.0603e-01,\n",
            "        -2.1606e-01,  1.0093e-01, -5.0148e-01, -1.1058e-01, -4.3455e-01,\n",
            "        -2.6785e-01, -2.0234e-01,  3.8320e-03, -4.9108e-01, -1.7642e-01,\n",
            "        -8.8971e-01, -2.7900e-01,  8.6387e-01, -1.7356e-02,  3.1210e-01,\n",
            "         4.1004e-01,  2.3199e-01, -6.0812e-01,  4.4763e-01, -8.9579e-01,\n",
            "        -3.8491e-02, -2.5772e-01,  3.9468e-01,  1.6186e+00, -5.4882e-01,\n",
            "        -3.0291e+00, -7.7845e-01, -3.2463e-01,  1.7658e+00,  9.7303e-01,\n",
            "        -3.9342e-01,  5.4811e-01,  1.3164e-02,  3.7850e-01,  2.4538e-01,\n",
            "         3.1079e-02,  2.3628e-01,  2.8901e-01,  2.7047e-02,  2.8985e-01,\n",
            "        -7.4523e-01,  1.1517e-02, -3.9456e-01, -5.7706e-01, -6.3604e-01,\n",
            "         3.1022e-01, -3.8317e-01, -7.7663e-02, -1.3539e+00,  1.8009e-02,\n",
            "         8.5646e-01,  3.8259e-02, -3.9437e-01,  4.4331e-01, -1.0802e+00,\n",
            "        -4.3159e-01,  1.4391e-01,  1.1854e-01, -5.6459e-01, -4.7966e-01,\n",
            "         2.2860e-01, -2.4369e-01, -4.2823e-01,  1.0366e+00, -8.3071e-01,\n",
            "         1.2460e-01,  2.0630e-01,  5.4232e-01,  1.1425e-01, -6.6927e-01],\n",
            "       device='cuda:0')\n",
            "tensor([-4.4295e-01,  5.9694e-02,  7.8306e-02, -2.4619e-01,  2.8411e-02,\n",
            "        -6.3084e-01,  3.7209e-02, -1.6568e-01, -7.3036e-01, -6.8152e-01,\n",
            "        -1.5946e-01, -4.4025e-01, -5.3630e-01,  2.4174e-01,  7.7513e-02,\n",
            "        -3.1366e-01,  3.3539e-01, -1.4214e-01, -1.2390e+00,  1.6170e-01,\n",
            "        -1.3486e-01, -2.2743e-01,  4.4955e-01, -7.2688e-01,  2.5063e-01,\n",
            "         1.1166e-01, -6.2308e-01, -5.5884e-01,  5.1252e-01,  3.6855e-01,\n",
            "         2.9996e-01,  7.0179e-01,  6.7464e-01,  4.0543e-01, -3.0825e-01,\n",
            "         8.3837e-01, -1.8986e-01, -1.7278e-01, -2.1306e-01,  3.5070e-01,\n",
            "        -4.1994e-01, -9.9697e-02,  7.5963e-01,  3.2975e-01, -2.2113e-01,\n",
            "        -1.2372e-01, -5.1361e-01, -6.8517e-01, -6.5545e-02, -1.7642e-01,\n",
            "         6.0858e-01, -7.4822e-02,  9.6863e-01,  5.0805e-01,  2.6777e-01,\n",
            "        -2.7093e+00, -1.0079e-01, -1.2588e-01,  1.2641e-01, -1.2384e-01,\n",
            "         4.0576e-01,  5.5333e-01,  1.5053e-01, -9.6734e-02,  2.8402e-01,\n",
            "        -2.3382e-01,  4.7452e-02,  1.4050e+00, -2.7471e-01,  6.4243e-01,\n",
            "        -5.1403e-01,  1.8748e-01, -9.9874e-01, -3.7344e-01, -1.4193e-01,\n",
            "        -2.7153e-01,  3.0842e-01,  9.3234e-01, -3.8388e-01,  3.6608e-01,\n",
            "         7.3780e-01, -1.7734e-01,  2.0051e-02, -2.4361e-01, -5.7102e-01,\n",
            "        -2.7266e-01, -5.6562e-01, -7.4104e-01,  1.6745e-01, -1.3076e+00,\n",
            "        -3.5900e-01, -7.5738e-01, -1.0948e-01,  5.3662e-01, -1.0914e+00,\n",
            "        -1.0287e-01,  5.8263e-04, -4.5603e-01, -4.7270e-02, -6.7599e-01],\n",
            "       device='cuda:0')\n",
            "tensor([-2.2048e-01, -1.1316e-01,  9.4277e-01, -3.9024e-01,  2.5004e-01,\n",
            "        -4.1651e-01, -1.4640e-01,  2.3628e-03, -1.2966e-01, -1.1173e-01,\n",
            "        -2.1546e-01, -8.6271e-01,  1.3817e-01,  3.3118e-01, -6.6500e-01,\n",
            "         3.7134e-01,  2.0050e-01, -3.4055e-01, -1.2422e+00, -7.6653e-01,\n",
            "        -1.1253e-02,  3.8440e-01, -5.0105e-02, -1.8869e-01,  1.0785e-01,\n",
            "         1.7502e-01, -1.0167e-01, -5.7925e-01,  2.3529e-01,  3.2626e-02,\n",
            "         3.2353e-01,  9.7457e-01,  4.5231e-01,  4.9740e-01, -8.8874e-01,\n",
            "         4.9170e-01,  1.1230e-01, -2.1484e-01,  9.3187e-02,  4.7039e-01,\n",
            "        -7.8776e-01, -6.8219e-01, -2.3741e-01,  2.2351e-01,  2.0269e-01,\n",
            "        -1.0166e+00,  1.3095e-01, -2.3654e-01,  3.1501e-01, -3.1880e-01,\n",
            "         5.9744e-01, -2.8722e-01,  2.9970e-01,  3.4877e-01, -1.6597e-01,\n",
            "        -2.8483e+00,  3.2219e-01, -7.8469e-01,  1.3754e+00,  1.5050e-01,\n",
            "        -8.5193e-01,  2.5303e-01,  2.0142e-01, -5.9176e-01,  8.9212e-02,\n",
            "        -3.5561e-01,  2.6522e-01,  1.1283e+00, -3.7250e-01,  9.4010e-01,\n",
            "        -5.2708e-01, -4.6361e-01, -8.1034e-01, -3.3479e-01,  1.0260e-01,\n",
            "        -4.1905e-01,  6.3775e-01,  4.5096e-02, -1.2385e+00,  2.1903e-01,\n",
            "         4.9145e-01,  3.6583e-01, -3.2024e-01, -5.1061e-02, -6.5049e-01,\n",
            "        -1.1894e-02,  2.0887e-01,  2.5857e-01, -2.3303e-01, -8.4911e-01,\n",
            "        -1.5466e-01, -3.3714e-01, -3.7272e-01, -2.9143e-01, -1.2799e+00,\n",
            "         2.8781e-01,  2.9473e-01, -3.2733e-01,  6.3016e-01,  3.6249e-01],\n",
            "       device='cuda:0')\n",
            "tensor([-0.3398,  0.2094,  0.4635, -0.6479, -0.3838,  0.0380,  0.1713,  0.1598,\n",
            "         0.4662, -0.0192,  0.4148, -0.3435,  0.2687,  0.0446,  0.4213, -0.4103,\n",
            "         0.1546,  0.0222, -0.6465,  0.2526,  0.0431, -0.1945,  0.4652,  0.4565,\n",
            "         0.6859,  0.0913,  0.2188, -0.7035,  0.1679, -0.3508, -0.1263,  0.6638,\n",
            "        -0.2582,  0.0365, -0.1361,  0.4025,  0.1429,  0.3813, -0.1228, -0.4589,\n",
            "        -0.2528, -0.3043, -0.1121, -0.2618, -0.2248, -0.4455,  0.2991, -0.8561,\n",
            "        -0.1450, -0.4909,  0.0083, -0.1749,  0.2752,  1.4401, -0.2124, -2.8435,\n",
            "        -0.2796, -0.4572,  1.6386,  0.7881, -0.5526,  0.6500,  0.0864,  0.3901,\n",
            "         1.0632, -0.3538,  0.4833,  0.3460,  0.8417,  0.0987, -0.2421, -0.2705,\n",
            "         0.0453, -0.4015,  0.1139,  0.0062,  0.0367,  0.0185, -1.0213, -0.2081,\n",
            "         0.6407, -0.0688, -0.5864,  0.3348, -1.1432, -0.1148, -0.2509, -0.4591,\n",
            "        -0.0968, -0.1795, -0.0634, -0.6741, -0.0689,  0.5360, -0.8777,  0.3180,\n",
            "        -0.3924, -0.2339,  0.4730, -0.0288], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
              "        True, True, True, True], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHRuHJaGKXJh"
      },
      "source": [
        "## ASSIGNMENT 2\n",
        "\n",
        "In this assigment we will show how the representations obtained for both occurrences of 'Washington' are different when they are obtained from Flair contextual-based embeddings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVrDecBtzvu3"
      },
      "source": [
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "# init Flair embedding\n",
        "flair_embedding_forward = FlairEmbeddings('news-forward')\n",
        "tokenized_sentence = Sentence('Washington University, which is located in Missouri, is named after George Washington.', use_tokenizer=True)\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4x3tR9lLlsB"
      },
      "source": [
        "+ TODO: compare the representations obtained for 'Washington' for both sentences, tokenized and raw."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ajmr-0JJLK4G",
        "outputId": "c6d40c74-a891-4866-afed-094862857d23"
      },
      "source": [
        "# TODO compare the Flair embeddings obtained for 'Washington'\n",
        "flair_embedding_forward.embed(tokenized_sentence)\n",
        "\n",
        "tokenized_sentence[0].get_embedding() == tokenized_sentence[13].get_embedding()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False,  ..., False, False, False], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNf91MDYQybN",
        "outputId": "b850b86c-49fc-400b-e1a1-8a6f0c33a99d"
      },
      "source": [
        "# TODO compare the Flair embeddings obtained for 'Washington'\n",
        "flair_embedding_forward.embed(sentence)\n",
        "\n",
        "tokenized_sentence[0].get_embedding() == tokenized_sentence[11].get_embedding()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False,  ..., False, False, False], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj3_18iBim-F"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Tagging\n",
        "\n",
        "Now we will learn how to tag our sentence using Flair pre-trained models for the following tasks:\n",
        "\n",
        "1. POS tagging\n",
        "3. Named Entity Recognition\n",
        "4. Frame Semantics (event detection)\n",
        "5. Polarity classification\n",
        "\n",
        "** Check the following link to see the list of available models and languages:**\n",
        "[Flair Tagging Info](https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_2_TAGGING.md)\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9zjAbXbkMzS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b6c4f0-743d-45dc-988a-726a1bfc78ab"
      },
      "source": [
        "pos_tagger = SequenceTagger.load('pos')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-01 18:33:58,078 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:33:58,080 The model key 'pos' now maps to 'https://huggingface.co/flair/pos-english' on the HuggingFace ModelHub\n",
            "2022-03-01 18:33:58,084  - The most current version of the model is automatically downloaded from there.\n",
            "2022-03-01 18:33:58,085  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/pos/en-pos-ontonotes-v0.5.pt)\n",
            "2022-03-01 18:33:58,088 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:33:58,253 loading file /root/.flair/models/pos-english/a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnCl3opclmH0"
      },
      "source": [
        "pos_tagger.predict(sentence)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5poo-5Ql1mZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23225345-a15c-4e42-bb65-9061af8f39fa"
      },
      "source": [
        "for postag in sentence.get_spans('pos'):\n",
        "  print(postag)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Span [1]: \"Washington\"   [− Labels: NNP (1.0)]\n",
            "Span [2]: \"University,\"   [− Labels: NNP (1.0)]\n",
            "Span [3]: \"which\"   [− Labels: WDT (1.0)]\n",
            "Span [4]: \"is\"   [− Labels: VBZ (1.0)]\n",
            "Span [5]: \"located\"   [− Labels: VBN (0.9999)]\n",
            "Span [6]: \"in\"   [− Labels: IN (1.0)]\n",
            "Span [7]: \"Missouri,\"   [− Labels: NNP (1.0)]\n",
            "Span [8]: \"is\"   [− Labels: VBZ (1.0)]\n",
            "Span [9]: \"named\"   [− Labels: VBN (1.0)]\n",
            "Span [10]: \"after\"   [− Labels: IN (0.9994)]\n",
            "Span [11]: \"George\"   [− Labels: NNP (1.0)]\n",
            "Span [12]: \"Washington.\"   [− Labels: NNP (1.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqaR_aymmKw7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c9184a7-8cb2-4180-dc7a-25a47afd2247"
      },
      "source": [
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Washington <NNP> University, <NNP> which <WDT> is <VBZ> located <VBN> in <IN> Missouri, <NNP> is <VBZ> named <VBN> after <IN> George <NNP> Washington. <NNP>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Smhnbxoojwdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa0820a-b2af-4c03-deea-260a91034dd2"
      },
      "source": [
        "chunker = SequenceTagger.load('chunk')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-01 18:33:59,097 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:33:59,102 The model key 'chunk' now maps to 'https://huggingface.co/flair/chunk-english' on the HuggingFace ModelHub\n",
            "2022-03-01 18:33:59,108  - The most current version of the model is automatically downloaded from there.\n",
            "2022-03-01 18:33:59,110  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/chunk/en-chunk-conll2000-v0.4.pt)\n",
            "2022-03-01 18:33:59,114 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:33:59,257 loading file /root/.flair/models/chunk-english/5b53097d6763734ee8ace8de92db67a1ee2528d5df9c6d20ec8e3e6f6470b423.d81b7fd7a38422f2dbf40f6449b1c63d5ae5b959863aa0c2c1ce9116902e8b22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbXQaTaMj56O"
      },
      "source": [
        "chunker.predict(sentence)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIy91gzlkGfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb46aafc-746d-498d-9194-549b32e688ec"
      },
      "source": [
        "for chunktag in sentence.get_spans('np'):\n",
        "  print(chunktag)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Span [1,2]: \"Washington University,\"   [− Labels: NP (0.7409)]\n",
            "Span [3]: \"which\"   [− Labels: NP (0.9995)]\n",
            "Span [4,5]: \"is located\"   [− Labels: VP (0.8574)]\n",
            "Span [6]: \"in\"   [− Labels: PP (1.0)]\n",
            "Span [7]: \"Missouri,\"   [− Labels: NP (0.9999)]\n",
            "Span [8,9]: \"is named\"   [− Labels: VP (0.9624)]\n",
            "Span [10]: \"after\"   [− Labels: PP (0.9981)]\n",
            "Span [11,12]: \"George Washington.\"   [− Labels: NP (0.798)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUJEv1Tlj-MG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98bff55f-85bf-4ccb-82ec-fd4ffd1acc7e"
      },
      "source": [
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Washington <NNP/B-NP> University, <NNP/E-NP> which <WDT/S-NP> is <VBZ/B-VP> located <VBN/E-VP> in <IN/S-PP> Missouri, <NNP/S-NP> is <VBZ/B-VP> named <VBN/E-VP> after <IN/S-PP> George <NNP/B-NP> Washington. <NNP/E-NP>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7iEd1O87dR1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666cda53-6a12-443f-9e7e-2a051e0a8292"
      },
      "source": [
        "ner_tagger = SequenceTagger.load('ner')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-01 18:33:59,991 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:33:59,999 The model key 'ner' now maps to 'https://huggingface.co/flair/ner-english' on the HuggingFace ModelHub\n",
            "2022-03-01 18:34:00,002  - The most current version of the model is automatically downloaded from there.\n",
            "2022-03-01 18:34:00,008  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt)\n",
            "2022-03-01 18:34:00,009 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:00,162 loading file /root/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_BqJpjM7nS0"
      },
      "source": [
        "ner_tagger.predict(sentence)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKsRwzPn85XV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984d2f3a-eb51-438e-9185-c5ae009329ae"
      },
      "source": [
        "# iterate over entities and print\n",
        "for entity in sentence.get_spans('ner'):\n",
        "    print(entity)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Span [1,2]: \"Washington University,\"   [− Labels: ORG (0.8766)]\n",
            "Span [7]: \"Missouri,\"   [− Labels: LOC (0.9987)]\n",
            "Span [11,12]: \"George Washington.\"   [− Labels: PER (0.9916)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sucDODzD9lud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ee54a2-b515-46c8-9270-b745855837b9"
      },
      "source": [
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Washington <NNP/B-NP/B-ORG> University, <NNP/E-NP/E-ORG> which <WDT/S-NP> is <VBZ/B-VP> located <VBN/E-VP> in <IN/S-PP> Missouri, <NNP/S-NP/S-LOC> is <VBZ/B-VP> named <VBN/E-VP> after <IN/S-PP> George <NNP/B-NP/B-PER> Washington. <NNP/E-NP/E-PER>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcTqR2-w-Iu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1d7ce0f-273e-4c57-c1bb-2af1a0eb5f40"
      },
      "source": [
        "sem_tagger = SequenceTagger.load('frame')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-01 18:34:03,370 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:03,375 The model key 'frame' now maps to 'https://huggingface.co/flair/frame-english' on the HuggingFace ModelHub\n",
            "2022-03-01 18:34:03,381  - The most current version of the model is automatically downloaded from there.\n",
            "2022-03-01 18:34:03,382  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/frame/en-frame-ontonotes-v0.4.pt)\n",
            "2022-03-01 18:34:03,384 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:03,560 loading file /root/.flair/models/frame-english/c397b8bbddf56e35a7d4b64295712a42a1a9b7ccf430dff76d03c8c7e26b9707.fd7786a36026b383ca73a1413c0a29aa1e67551621b805a0d28ca547636353b9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbZY7xMQiBZL"
      },
      "source": [
        "sem_tagger.predict(sentence)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmddT1dziPfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "816dc6dd-67ba-429f-afa3-17918958fdfd"
      },
      "source": [
        "for event in sentence.get_spans('frame'):\n",
        "  print(event)\n",
        "print(sentence.to_tagged_string())"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Span [4]: \"is\"   [− Labels: be.03 (0.9955)]\n",
            "Span [5]: \"located\"   [− Labels: locate.01 (0.9831)]\n",
            "Span [8]: \"is\"   [− Labels: be.03 (0.9987)]\n",
            "Span [9]: \"named\"   [− Labels: name.01 (0.7091)]\n",
            "Washington <NNP/B-NP/B-ORG> University, <NNP/E-NP/E-ORG> which <WDT/S-NP> is <VBZ/B-VP/be.03> located <VBN/E-VP/locate.01> in <IN/S-PP> Missouri, <NNP/S-NP/S-LOC> is <VBZ/B-VP/be.03> named <VBN/E-VP/name.01> after <IN/S-PP> George <NNP/B-NP/B-PER> Washington. <NNP/E-NP/E-PER>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yxv9Xfxiz4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6c7f528-e9d4-4c1f-dd83-294304336479"
      },
      "source": [
        "print(sentence.to_dict(tag_type='pos'))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Washington University, which is located in Missouri, is named after George Washington.', 'labels': [], 'entities': [{'text': 'Washington', 'start_pos': 0, 'end_pos': 10, 'labels': [NNP (1.0)]}, {'text': 'University,', 'start_pos': 11, 'end_pos': 22, 'labels': [NNP (1.0)]}, {'text': 'which', 'start_pos': 23, 'end_pos': 28, 'labels': [WDT (1.0)]}, {'text': 'is', 'start_pos': 29, 'end_pos': 31, 'labels': [VBZ (1.0)]}, {'text': 'located', 'start_pos': 32, 'end_pos': 39, 'labels': [VBN (0.9999)]}, {'text': 'in', 'start_pos': 40, 'end_pos': 42, 'labels': [IN (1.0)]}, {'text': 'Missouri,', 'start_pos': 43, 'end_pos': 52, 'labels': [NNP (1.0)]}, {'text': 'is', 'start_pos': 53, 'end_pos': 55, 'labels': [VBZ (1.0)]}, {'text': 'named', 'start_pos': 56, 'end_pos': 61, 'labels': [VBN (1.0)]}, {'text': 'after', 'start_pos': 62, 'end_pos': 67, 'labels': [IN (0.9994)]}, {'text': 'George', 'start_pos': 68, 'end_pos': 74, 'labels': [NNP (1.0)]}, {'text': 'Washington.', 'start_pos': 75, 'end_pos': 86, 'labels': [NNP (1.0)]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Szh3q5AlaTe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f65f166-9cfb-423b-c30f-b76df0aef414"
      },
      "source": [
        "print(sentence.to_dict(tag_type='chunk'))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Washington University, which is located in Missouri, is named after George Washington.', 'labels': [], 'entities': []}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6WEuLoljCR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a074aba-8b86-40a7-ac35-90608ae92d3f"
      },
      "source": [
        "print(sentence.to_dict(tag_type='ner'))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Washington University, which is located in Missouri, is named after George Washington.', 'labels': [], 'entities': [{'text': 'Washington University,', 'start_pos': 0, 'end_pos': 22, 'labels': [ORG (0.8766)]}, {'text': 'Missouri,', 'start_pos': 43, 'end_pos': 52, 'labels': [LOC (0.9987)]}, {'text': 'George Washington.', 'start_pos': 68, 'end_pos': 86, 'labels': [PER (0.9916)]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0z0nr2QjG5Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e70b39d4-aed1-4cbb-e87b-5cbbe96a9a95"
      },
      "source": [
        "print(sentence.to_dict(tag_type='frame'))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': 'Washington University, which is located in Missouri, is named after George Washington.', 'labels': [], 'entities': [{'text': 'is', 'start_pos': 29, 'end_pos': 31, 'labels': [be.03 (0.9955)]}, {'text': 'located', 'start_pos': 32, 'end_pos': 39, 'labels': [locate.01 (0.9831)]}, {'text': 'is', 'start_pos': 53, 'end_pos': 55, 'labels': [be.03 (0.9987)]}, {'text': 'named', 'start_pos': 56, 'end_pos': 61, 'labels': [name.01 (0.7091)]}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2DRh1z5mZPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18651c48-e30b-4f96-dfd4-091c5078ca5f"
      },
      "source": [
        "polarity_classifier = TextClassifier.load('en-sentiment')"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-01 18:34:05,409 loading file /root/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEWoXN31m90v"
      },
      "source": [
        "polarity_classifier.predict(sentence)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfEK7YplnB24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aac41386-9bb7-42fb-8e6a-ee9a5f09b85e"
      },
      "source": [
        "print(sentence.to_tagged_string())\n",
        "print(sentence.labels)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Washington <NNP/B-NP/B-ORG> University, <NNP/E-NP/E-ORG> which <WDT/S-NP> is <VBZ/B-VP/be.03> located <VBN/E-VP/locate.01> in <IN/S-PP> Missouri, <NNP/S-NP/S-LOC> is <VBZ/B-VP/be.03> named <VBN/E-VP/name.01> after <IN/S-PP> George <NNP/B-NP/B-PER> Washington. <NNP/E-NP/E-PER>\n",
            "[POSITIVE (0.9722)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8dStO99pjXN"
      },
      "source": [
        "## ASSIGNMENT 3\n",
        "\n",
        "Check out the following list of sentences and perform the following tasks using the Flair system and models:\n",
        "\n",
        "1. Perform POS tagging and Named Entity Recognition on sentences 1-4.\n",
        "2. Chunking and Frame detection for sentences 5-6.\n",
        "3. Sentiment Analysis for sentences 7-8.\n",
        "\n",
        "**Do not repeat the instructions, use the loop structure to annotate and display the annotations of every sentence in one step per task.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogtPRzoL-1m9"
      },
      "source": [
        "sentence_1 = Sentence('Jackson is placed in Microsoft located in Redmond .')\n",
        "sentence_2 = Sentence('Redmond is coming to New York city .')\n",
        "sentence_3 = Sentence('Redmond is coming to New York City .')\n",
        "sentence_4 = Sentence('Redmond is coming to New York City.')\n",
        "sentence_5 = Sentence('Redmond returned to New York City to return his hat .')\n",
        "sentence_6 = Sentence('He had a look at different hats .')\n",
        "sentence_7 = Sentence('This film hurts.')\n",
        "sentence_8 = Sentence('It is so bad that I am confused.')"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Put the phrases in a list to be able to use a loop.\n",
        "\n",
        "all_sentences= [sentence_1,sentence_2,sentence_3,sentence_4,sentence_5,sentence_6,sentence_7,sentence_8]"
      ],
      "metadata": {
        "id": "SxlZICWR9IqY"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from flair.models.sequence_tagger_model import MultiTagger\n",
        "\n",
        "tagger1= MultiTagger.load([\"pos\",\"ner\"]) #1\n",
        "tagger2= MultiTagger.load([\"chunk\",\"frame\"]) #2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLDH4qaM9J1T",
        "outputId": "41a11498-2a34-4da0-aee3-e93d1b47da24"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-03-01 18:34:07,959 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:07,965 The model key 'pos' now maps to 'https://huggingface.co/flair/pos-english' on the HuggingFace ModelHub\n",
            "2022-03-01 18:34:07,967  - The most current version of the model is automatically downloaded from there.\n",
            "2022-03-01 18:34:07,969  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/pos/en-pos-ontonotes-v0.5.pt)\n",
            "2022-03-01 18:34:07,972 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:08,115 loading file /root/.flair/models/pos-english/a9a73f6cd878edce8a0fa518db76f441f1cc49c2525b2b4557af278ec2f0659e.121306ea62993d04cd1978398b68396931a39eb47754c8a06a87f325ea70ac63\n",
            "2022-03-01 18:34:08,635 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:08,638 The model key 'ner' now maps to 'https://huggingface.co/flair/ner-english' on the HuggingFace ModelHub\n",
            "2022-03-01 18:34:08,642  - The most current version of the model is automatically downloaded from there.\n",
            "2022-03-01 18:34:08,645  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt)\n",
            "2022-03-01 18:34:08,647 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:08,787 loading file /root/.flair/models/ner-english/4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n",
            "2022-03-01 18:34:10,881 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:10,884 The model key 'chunk' now maps to 'https://huggingface.co/flair/chunk-english' on the HuggingFace ModelHub\n",
            "2022-03-01 18:34:10,889  - The most current version of the model is automatically downloaded from there.\n",
            "2022-03-01 18:34:10,890  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/chunk/en-chunk-conll2000-v0.4.pt)\n",
            "2022-03-01 18:34:10,894 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:11,050 loading file /root/.flair/models/chunk-english/5b53097d6763734ee8ace8de92db67a1ee2528d5df9c6d20ec8e3e6f6470b423.d81b7fd7a38422f2dbf40f6449b1c63d5ae5b959863aa0c2c1ce9116902e8b22\n",
            "2022-03-01 18:34:11,564 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:11,565 The model key 'frame' now maps to 'https://huggingface.co/flair/frame-english' on the HuggingFace ModelHub\n",
            "2022-03-01 18:34:11,570  - The most current version of the model is automatically downloaded from there.\n",
            "2022-03-01 18:34:11,576  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/frame/en-frame-ontonotes-v0.4.pt)\n",
            "2022-03-01 18:34:11,577 --------------------------------------------------------------------------------\n",
            "2022-03-01 18:34:11,722 loading file /root/.flair/models/frame-english/c397b8bbddf56e35a7d4b64295712a42a1a9b7ccf430dff76d03c8c7e26b9707.fd7786a36026b383ca73a1413c0a29aa1e67551621b805a0d28ca547636353b9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Perform POS tagging and Named Entity Recognition on sentences 1-4.\n",
        "\n",
        "for i in range(4):\n",
        "  tagger1.predict(all_sentences[i])\n",
        "  print(all_sentences[i].to_tagged_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H1u_1m--M-y",
        "outputId": "88a2a150-1a33-4a8b-ffe2-f1602583c322"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jackson <NNP/S-PER> is <VBZ> placed <VBN> in <IN> Microsoft <NNP/S-ORG> located <VBN> in <IN> Redmond <NNP/S-LOC> . <.>\n",
            "Redmond <NNP/S-PER> is <VBZ> coming <VBG> to <IN> New <NNP/B-LOC> York <NNP/E-LOC> city <NN> . <.>\n",
            "Redmond <NNP/S-PER> is <VBZ> coming <VBG> to <IN> New <NNP/B-LOC> York <NNP/I-LOC> City <NNP/E-LOC> . <.>\n",
            "Redmond <NNP/S-PER> is <VBZ> coming <VBG> to <IN> New <NNP/B-LOC> York <NNP/I-LOC> City <NNP/E-LOC> . <.>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Chunking and Frame detection for sentences 5-6.\n",
        "\n",
        "\n",
        "for i in range(4,6):\n",
        "  tagger2.predict(all_sentences[i])\n",
        "  print(all_sentences[i].to_tagged_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzgbmZFX_IUy",
        "outputId": "0ae603e1-2242-44bc-912d-d891658f991e"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Redmond <S-NP> returned <S-VP/return.01> to <S-PP> New <B-NP> York <I-NP> City <E-NP> to <B-VP> return <E-VP/return.02> his <B-NP> hat <E-NP> .\n",
            "He <S-NP> had <S-VP/have.03> a <B-NP> look <E-NP/look.01> at <S-PP> different <B-NP> hats <E-NP> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Sentiment Analysis for sentences 7-8.\n",
        "\n",
        "for i in range(6,8):\n",
        "  polarity_classifier.predict(all_sentences[i])\n",
        "  print(all_sentences[i].labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wotZsF3_UgE",
        "outputId": "632325df-206a-4531-d393-c8e72c8bd6d7"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NEGATIVE (0.9999)]\n",
            "[NEGATIVE (0.9999)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENKOC4Q6x6Vc"
      },
      "source": [
        "## ASSIGNMENT 4 (BONUS)\n",
        "\n",
        "In this task you will be annotating a movie review at document and sentence level.\n",
        "\n",
        "1. Open the text in this file: '/content/drive/My Drive/Colab Notebooks/2021-ILTAPP/resources/movie-review.txt'\n",
        "2. Predict Named Entities and Sentiment for the **whole document**.\n",
        "3. Predict Named Entities and Sentiment for each of the sentences in the document.\n",
        "> 3.1 Hint: You will need to segment the document at sentence level using the segtok segmenter and store each sentence as a Sentence object. The final result must be a list of Sentence objects. The segtok segmenter is used as in the following code snippet:\n",
        "\n",
        "```\n",
        "from segtok.segmenter import split_single\n",
        "split_single(docText)\n",
        "```\n",
        "\n",
        "4. Print both the sentiment classification output and Named Entities.\n",
        "5. Spot the differences in the annotations when performed at document and at sentence level. Write the difference at the end of this notebook.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "with open(\"/content/drive/MyDrive/2022-ILTAPP/resources/movie-review.txt\", \"r\") as file:\n",
        "  data = file.read()\n",
        "\n",
        "tokenized_text = Sentence(data)\n",
        "\n",
        "ner_tagger.predict(tokenized_text)\n",
        "polarity_classifier.predict(tokenized_text)\n",
        "\n",
        "print(tokenized_text.to_tagged_string)\n",
        "print(tokenized_text.labels)\n",
        "\n",
        "listsentences = []\n",
        "for sent in split_single(data):\n",
        "  listsentences.append(Sentence(sent))\n",
        "\n",
        "ner_tagger.predict(listsentences)\n",
        "polarity_classifier.predict(listsentences)\n",
        "for item in listsentences:\n",
        "    print(item.to_tagged_string())\n",
        "    print(item.labels)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bqZxgx2KC3J",
        "outputId": "ab6af5ae-7dfa-4fe5-8395-8c0d1ddf4544"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "<bound method Sentence.to_tagged_string of Sentence: \"Once again Mr. Costner has dragged out a movie for far longer than necessary . Aside from the terrific sea rescue sequences , of which there are very few I just did not care about any of the characters . Most of us have ghosts in the closet , and Costner 's character are realized early on , and then forgotten until much later , by which time I did not care . The character we should really care about is a very cocky , overconfident Ashton Kutcher . The problem is he comes off as kid who thinks he 's better than anyone else around him and shows no signs of a cluttered closet . His only obstacle appears to be winning over Costner . Finally when we are well past the half way point of this stinker , Costner tells us all about Kutcher 's ghosts . We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing . No magic here , it was all I could do to keep from turning it off an hour in .\"   [− Tokens: 187  − Token-Labels: \"Once again Mr. Costner <S-PER> has dragged out a movie for far longer than necessary . Aside from the terrific sea rescue sequences , of which there are very few I just did not care about any of the characters . Most of us have ghosts in the closet , and Costner <S-PER> 's character are realized early on , and then forgotten until much later , by which time I did not care . The character we should really care about is a very cocky , overconfident Ashton <B-PER> Kutcher <E-PER> . The problem is he comes off as kid who thinks he 's better than anyone else around him and shows no signs of a cluttered closet . His only obstacle appears to be winning over Costner <S-PER> . Finally when we are well past the half way point of this stinker , Costner <S-PER> tells us all about Kutcher <S-PER> 's ghosts . We are told why Kutcher <S-PER> is driven to be the best with no prior inkling or foreshadowing . No magic here , it was all I could do to keep from turning it off an hour in .\"  − Sentence-Labels: {'label': [NEGATIVE (1.0)]}]>\n",
            "[NEGATIVE (1.0)]\n",
            "2022-03-01 18:37:32,245 Warning: An empty Sentence was created! Are there empty strings in your dataset?\n",
            "2022-03-01 18:37:32,247 Ignore 1 sentence(s) with no tokens.\n",
            "Once again Mr. Costner <S-PER> has dragged out a movie for far longer than necessary .\n",
            "[NEGATIVE (0.999)]\n",
            "Aside from the terrific sea rescue sequences , of which there are very few I just did not care about any of the characters .\n",
            "[NEGATIVE (1.0)]\n",
            "Most of us have ghosts in the closet , and Costner <S-PER> 's character are realized early on , and then forgotten until much later , by which time I did not care .\n",
            "[NEGATIVE (1.0)]\n",
            "The character we should really care about is a very cocky , overconfident Ashton <B-PER> Kutcher <E-PER> .\n",
            "[NEGATIVE (0.9915)]\n",
            "The problem is he comes off as kid who thinks he 's better than anyone else around him and shows no signs of a cluttered closet .\n",
            "[NEGATIVE (0.9198)]\n",
            "His only obstacle appears to be winning over Costner <S-PER> .\n",
            "[POSITIVE (0.9816)]\n",
            "Finally when we are well past the half way point of this stinker , Costner <S-PER> tells us all about Kutcher <S-PER> 's ghosts .\n",
            "[NEGATIVE (0.9605)]\n",
            "We are told why Kutcher <S-PER> is driven to be the best with no prior inkling or foreshadowing .\n",
            "[POSITIVE (0.9991)]\n",
            "No magic here , it was all I could do to keep from turning it off an hour in .\n",
            "[NEGATIVE (0.9999)]\n",
            "\n",
            "[]\n"
          ]
        }
      ]
    }
  ]
}